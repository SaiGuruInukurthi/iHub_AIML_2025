DATASET USAGE MAPPING
===================

This file maps each notebook to the datasets it uses. Make sure you have the required datasets in the repository root directory before running the notebooks.

📊 AVAILABLE DATASETS:
---------------------
- car_evaluation.csv      # Car evaluation dataset (1728 records, 7 attributes)
- covid_19_data.csv       # COVID-19 dataset with confirmed cases, deaths, recoveries by date/location ⚠️ REQUIRED for Mod5_project
- diabetes.csv            # Pima Indian Diabetes dataset (768 records, 9 features) ⚠️ REQUIRED for Mod3_project
- INDIA_685.csv           # India demographic/geographic dataset
- reviews.csv             # Product/service reviews dataset
- sequences.fasta         # Biological sequence data (DNA/protein sequences)
- spam.csv                # Email spam classification dataset
- Mall_Customers.csv      # Mall customer segmentation dataset (auto-downloaded by Mod5_Lab3)
- Wholesale customers data.csv  # Wholesale customer dataset (auto-downloaded by Mod5_Lab3)
- lotus.jpg               # Sample image for convolution operations (auto-downloaded by Mod6_Lab3)
- german_traffic_signs_dataset.zip  # German Traffic Sign dataset for transfer learning (auto-downloaded by Mod6_Lab3)

📓 NOTEBOOK-DATASET MAPPING:
----------------------------

MODULE 1 - FOUNDATIONS:
----------------------
📒 Mod1_Lab1_Features.ipynb ✅ ENHANCED & COMPLETE
   └── Datasets: MNIST digits (from Keras), Wikipedia articles (auto-downloaded), synthetic text data
   └── External: None required (all data downloaded/generated automatically)
   └── Analysis: N-gram text analysis, image feature extraction, multi-language comparison
   └── Features: Character n-grams (1-5 grams), image features (sum, hull, hole, boundary, custom)
   └── Note: Comprehensive feature engineering notebook with exploration questions answered

📒 Mod1_Lab2_ML_terms_and_metrics.ipynb
   └── Datasets: Built-in sklearn datasets
   └── External: None required

📒 Mod1_Lab3_Data_Augmentation.ipynb
   └── Datasets: Built-in sklearn datasets, synthetic data
   └── External: None required

📒 Mod1_Lab4_Transforming_data_using_linear_algebra.ipynb
   └── Datasets: Built-in sklearn datasets, generated matrices
   └── External: None required

MODULE 2 - DIMENSIONALITY REDUCTION:
-----------------------------------
📒 Mod2_Lab1_Basic_Plots.ipynb
   └── Datasets: Built-in sklearn datasets (Iris)
   └── External: None required

📒 Mod2_Lab2_Principal_Components_Analysis_(PCA).ipynb
   └── Datasets: Built-in sklearn datasets (Iris, Wine, Digits)
   └── External: None required

📒 Mod2_Lab4_Manifold_Learning_Methods.ipynb
   └── Datasets: Built-in sklearn datasets (Swiss roll, S-curve)
   └── External: None required

📒 Mod2_Project.ipynb ⚠️ ENHANCED PROJECT
   └── Datasets: SARS-CoV-2 genomic analysis project
   └── External: INDIA_685.csv, sequences.fasta ⚠️ REQUIRED
   └── Analysis: K-mer profiling, mutation analysis, PCA, t-SNE, ISOMAP
   └── Note: Advanced bioinformatics project with dimensionality reduction

MODULE 3 - K-NEAREST NEIGHBORS:
-------------------------------
📒 Mod3_Lab1_Understanding_Distance_metrics_and_Introduction_to_KNN.ipynb
   └── Datasets: Built-in sklearn datasets (Iris)
   └── External: None required

📒 Mod3_Lab2_Using_KNN_for_Text_Classification.ipynb
   └── Datasets: Built-in datasets, text data generation
   └── External: reviews.csv (generated within notebook)
   └── Note: Creates reviews.csv file during execution

📒 Mod3_Lab3_Implementing_KNN_from_scratch_and_visualize_Algorithm_performance.ipynb
   └── Datasets: Built-in sklearn datasets (Iris)
   └── External: car_evaluation.csv ⚠️ REQUIRED
   └── Note: This notebook requires car_evaluation.csv for Task 3-6

📒 Mod3_project.ipynb ✅ COMPLETE PROJECT
   └── Dataset: diabetes.csv ⚠️ REQUIRED
   └── Purpose: Diabetes prediction in Pima Indian Women using KNN classification
   └── Analysis: Comprehensive EDA, feature scaling comparison, K-value optimization
   └── Tasks Completed: 
       • Task 1: Correlation analysis with heatmap visualization
       • Task 2: Pairplot analysis with diabetes outcome as hue
       • Task 3: Pedigree function vs diabetes boxplot analysis
       • Task 4: Pregnancies vs diabetes relationship visualization
       • Task 5: Age vs diabetes outcome analysis
       • Task 6: KNN error rate optimization with K-value selection
       • Task 7: MinMax scaling implementation and performance comparison
       • Task 8: Voronoi diagram visualization with PCA dimensionality reduction
       • Task 9: Comprehensive K-Fold cross-validation analysis
   └── Features: 8 predictive features (Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age)
   └── Scaling Methods: StandardScaler, MinMaxScaler with performance comparison
   └── Visualizations: Correlation heatmaps, boxplots, pairplots, decision boundaries, Voronoi diagrams
   └── Environment: mod3_project_venv (dedicated virtual environment)

MODULE 4 - GRADIENT DESCENT:
----------------------------
📒 Mod4_Lab1_Perceptron_and_Gradient_Descent.ipynb
   └── Datasets: Built-in sklearn datasets, synthetic data
   └── External: None required

📒 Mod4_Lab2_Introduction_to_Gradient_Descent.ipynb
   └── Datasets: Synthetic polynomial data, generated datasets
   └── External: None required

📒 Mod4_Lab3_Gradient_Descent.ipynb
   └── Datasets: Synthetic data, mathematical functions
   └── External: None required

📒 Mod4_project.ipynb ✅ COMPLETE PROJECT
   └── Dataset: Synthetic mathematical functions and linear regression data
   └── Purpose: Comprehensive gradient descent optimization and perceptron implementation
   └── Analysis: Multi-dimensional cost function optimization, learning rate analysis, 3D gradient descent
   └── Tasks Completed:
       • Task 1: Basic gradient descent implementation with step-by-step optimization
       • Task 2: Advanced function g(x) = x⁴ - 4x² + 5 with derivative implementation
       • Task 3: Side-by-side plotting of cost functions and derivatives
       • Task 4: Complex function h(x) = x⁵ - 2x⁴ + 2 implementation and visualization
       • Task 5: Multiple learning rate experiments (0.0005, 0.001, 0.002)
       • Task 6: Learning rate comparison with comprehensive visualization
       • Task 7: Cost reduction analysis with detailed iteration tracking
       • Task 8: 3D function f(x,y) = 1/(3^(-x²-y²) + 1) implementation
       • Task 9: Partial derivatives mathematical formulation
       • Task 10: Partial derivative functions fpx/fpy for gradient descent
   └── Mathematical Functions: 
       • f(x) = x² + x + 1 (basic quadratic optimization)
       • g(x) = x⁴ - 4x² + 5 (multiple minima analysis)
       • h(x) = x⁵ - 2x⁴ + 2 (divergence and overflow examples)
       • f(x,y) = 1/(3^(-x²-y²) + 1) (3D optimization with partial derivatives)
       • MSE functions for linear regression
   └── Visualizations: 2D/3D surface plots, contour plots, wireframes, cost reduction analysis
   └── Learning Rate Analysis: Convergence comparison, step size analysis, final convergence values
   └── Environment: mod4_project_venv (dedicated virtual environment)
   └── Dependencies: matplotlib, numpy, sympy, scikit-learn, scipy, mpl_toolkits.mplot3d

MODULE 5 - LINEAR REGRESSION & CLUSTERING:
------------------------------------------
📒 Mod5_Lab1_Linear_Regression_MSE_and_Polynomial_Regression.ipynb
   └── Datasets: California Housing (downloaded from URL)
   └── External: None required (auto-downloaded)
   └── URL: https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv

📒 Mod5_Lab2_Loss_Functions.ipynb
   └── Datasets: Built-in sklearn datasets (Diabetes, California Housing), BigMart dataset
   └── External: None required (auto-downloaded)
   └── URL: https://raw.githubusercontent.com/PranavTadimeti/Regression-lab2/main/BigMart-train.csv

📒 Mod5_Lab3_Clustering.ipynb
   └── Datasets: Built-in sklearn datasets (Iris, Digits), clustering datasets
   └── External: Mall_Customers.csv, Wholesale customers data.csv ⚠️ AUTO-DOWNLOADED
   └── Note: Downloads Mall_Customers.csv and Wholesale customers data.csv during execution

📒 Mod5_project.ipynb ✅ COMPLETE PROJECT
   └── Dataset: covid_19_data.csv ⚠️ REQUIRED
   └── Purpose: COVID-19 regression analysis using linear, polynomial, and ridge regression
   └── Analysis: Comprehensive COVID-19 data analysis with multiple regression techniques
   └── Tasks Completed:
       • Task 1: Load COVID-19 data into pandas dataframe
       • Task 2: Create cumulative dataframe (cases, deaths, recoveries by date)
       • Task 3: Create "closed cases" column (deaths + recoveries)
       • Task 4: Create "active cases" column (confirmed - closed)
       • Task 5: Plot total cases over time with trend analysis
       • Task 6: Plot active vs closed cases comparison
       • Task 7: Calculate growth factors for all case types
       • Task 8: Visualize growth factors with comparative plots
       • Part 2: Multiple regression model implementations and comparisons
   └── Features: 
       • Data preprocessing and temporal analysis
       • Linear regression with performance metrics
       • Polynomial regression (degree=5) with feature transformation
       • Ridge regression with hyperparameter tuning (BayesianRidge)
       • Polynomial Ridge regression with cross-validation
       • Model comparison using MAE and MSE metrics
   └── Regression Models: Linear, Polynomial (degree=5), Ridge, Polynomial Ridge
   └── Visualizations: Time series plots, growth factor analysis, prediction comparisons
   └── Best Model: Ridge Polynomial Regression (lowest MAE/MSE values)
   └── Environment: Uses main .venv environment with comprehensive ML packages

MODULE 6 - NEURAL NETWORKS:
---------------------------
📒 Mod6_Lab1_Implementing_forward_propagation_and_back_propagation.ipynb
   └── Datasets: Built-in sklearn datasets (Iris)
   └── External: None required

📒 Mod6_Lab2_Training_a_Neural_Network.ipynb
   └── Datasets: Built-in sklearn datasets (Iris), MNIST (from torchvision)
   └── External: None required (auto-downloaded)
   └── Analysis: Neural network fundamentals, forward/backward propagation implementation
   └── Features: Custom neural network class, gradient descent, sigmoid activation
   └── Note: Tutorial notebook demonstrating neural network training from scratch

📒 Mod6_Lab3_CNN_&_Architectures.ipynb ✅ COMPLETE WITH ANSWERS
   └── Datasets: MNIST (from torchvision), German Traffic Signs dataset
   └── External Images: lotus.jpg (for convolution examples)
   └── Auto-downloads: german_traffic_signs_dataset.zip (from Google Drive)
   └── Analysis: Convolutional operations, CNN visualization, transfer learning
   └── Architectures: Custom CNN, ResNet18, transfer learning comparison
   └── Features: Conv2D operations, pooling, fine-tuning vs feature extraction
   └── Note: Complete with exercise answers on transfer learning and data augmentation

MODULE 0 - MATHEMATICAL FOUNDATIONS:
-----------------------------------
📒 Mod0_Linear_Algebra.ipynb ✅ ENHANCED & COMPLETE
   └── Datasets: Built-in sample images (scikit-image astronaut), generated matrices
   └── External: None required (all data generated programmatically)
   └── Analysis: Comprehensive linear algebra operations and visualizations
   └── Features: Matrix operations, SVD, eigendecomposition, system solving, image compression
   └── Note: Advanced mathematical notebook with practical examples and SVD image reconstruction

📒 Mod0_Probability_Basics.ipynb ✅ CONFIGURED & COMPLETE
   └── Datasets: Online grades dataset, synthetic probability distributions, generated statistical data
   └── External: grades.csv (auto-downloaded from archive.org)
   └── URL: https://archive.org/download/ml-fundamentals-data/machine-learning-fundamentals-data/grades.csv
   └── Analysis: Probability theory, statistical distributions, descriptive statistics, probability plots
   └── Features: Fractions, combinatorics, normal/binomial/Poisson distributions, statistical measures
   └── Note: Comprehensive probability foundations with real student grades dataset analysis

DATASET DETAILS:
===============

🔹 car_evaluation.csv
   Purpose: Multi-class classification
   Features: buying, maint, doors, persons, lug_boot, safety, class
   Used by: Mod3_Lab3 (Tasks 3-6: Confusion matrix, classification report, decision boundary, Voronoi diagram)
   Size: 1,728 records
   Classes: 4 (unacc, acc, good, vgood)

🔹 covid_19_data.csv
   Purpose: COVID-19 regression analysis and time series prediction
   Features: ObservationDate, Province/State, Country/Region, Last Update, Confirmed, Deaths, Recovered
   Used by: Mod5_project.ipynb ⚠️ REQUIRED
   Records: Temporal COVID-19 data with daily case counts by location
   Analysis: Linear regression, polynomial regression, ridge regression for case prediction
   Tasks: 8 data analysis tasks + comprehensive regression modeling (Part 2)
   Models: Linear, Polynomial (degree=5), Ridge, Polynomial Ridge with hyperparameter tuning
   Note: Early pandemic data for regression analysis, growth factor calculations, and model comparison

🔹 diabetes.csv
   Purpose: Binary classification for diabetes prediction in Pima Indian Women
   Features: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome
   Used by: Mod3_project.ipynb ⚠️ REQUIRED
   Size: 768 records (500 non-diabetic, 268 diabetic)
   Classes: 2 (0: non-diabetic, 1: diabetic)
   Analysis: EDA with correlation analysis, feature scaling comparison, KNN optimization
   Note: Core dataset for comprehensive diabetes prediction project with 9 complete tasks

🔹 INDIA_685.csv
   Purpose: SARS-CoV-2 genomic metadata for Indian strains
   Used by: Mod2_Project.ipynb ⚠️ REQUIRED
   Features: Contains strain metadata, location information, collection dates
   Size: 685 records of Indian SARS-CoV-2 samples
   Analysis: Geographic clustering, mutation profiling by state

🔹 reviews.csv
   Purpose: Text classification, sentiment analysis
   Used by: Mod3_Lab2 (generated during execution)
   Note: This file is created by the notebook, not required as input

🔹 sequences.fasta
   Purpose: SARS-CoV-2 genome sequences for bioinformatics analysis
   Used by: Mod2_Project.ipynb ⚠️ REQUIRED
   Format: FASTA format containing 685 SARS-CoV-2 genome sequences
   Analysis: K-mer profiling (7-mer), mutation detection, sequence clustering
   Size: 685 complete genome sequences (~30KB each)
   Note: Core dataset for genomic analysis and dimensionality reduction

🔹 spam.csv
   Purpose: Binary classification (spam detection)
   Used by: Currently not used in any notebook (reserved for future labs)
   Note: May be used in text classification or advanced ML modules

🔹 Mall_Customers.csv
   Purpose: Customer segmentation clustering analysis
   Used by: Mod5_Lab3 (Exercise 4: Customer segmentation)
   Features: CustomerID, Gender, Age, Annual Income, Spending Score
   Size: 200 records
   Note: Auto-downloaded during Mod5_Lab3 execution

🔹 Wholesale customers data.csv
   Purpose: Wholesale customer clustering analysis
   Used by: Mod5_Lab3 (Exercise 4: Business clustering analysis)
   Features: Channel, Region, Fresh, Milk, Grocery, Frozen, Detergents_Paper, Delicassen
   Size: 440 records  
   Note: Auto-downloaded during Mod5_Lab3 execution

QUICK REFERENCE:
===============

MUST HAVE FOR BASIC FUNCTIONALITY:
- No external datasets required for Module 0 (Mathematical Foundations)
- No external datasets required for Modules 1, 4, and 6
- car_evaluation.csv REQUIRED for Mod3_Lab3
- diabetes.csv REQUIRED for Mod3_project
- covid_19_data.csv REQUIRED for Mod5_project
- INDIA_685.csv + sequences.fasta REQUIRED for Mod2_Project (Enhanced)
- No external datasets required for Mod4_project (uses synthetic mathematical functions)

AUTO-DOWNLOADED DURING EXECUTION:
- MNIST dataset (Mod1_Lab1 - via Keras)
- Wikipedia articles (Mod1_Lab1 - multi-language content)
- California Housing dataset (Mod5_Lab1, Mod5_Lab2 - from URL)
- BigMart dataset (Mod5_Lab2 - from URL)
- Mall_Customers.csv (Mod5_Lab3 - from Google Drive)
- Wholesale customers data.csv (Mod5_Lab3 - from Google Drive)

OPTIONAL/FUTURE USE:
- INDIA_685.csv (not currently used)
- sequences.fasta (not currently used)  
- spam.csv (not currently used)

GENERATED DURING EXECUTION:
- reviews.csv (created by Mod3_Lab2)
- Synthetic text data (created by Mod1_Lab1 for different source analysis)

TROUBLESHOOTING:
===============

❌ FileNotFoundError: car_evaluation.csv
   Solution: Download car_evaluation.csv and place in repository root

❌ FileNotFoundError: reviews.csv  
   Solution: Run Mod3_Lab2 first to generate this file, or create manually

❌ FileNotFoundError: Mall_Customers.csv or Wholesale customers data.csv
   Solution: Run Mod5_Lab3 cells that download these files, or check internet connection

❌ URL download failures (Module 5 datasets)
   Solution: Check internet connection, try running download cells again

❌ Missing sklearn datasets
   Solution: Install scikit-learn: pip install scikit-learn

❌ FASTA file format issues
   Solution: Install biopython: pip install biopython

❌ PyTorch/TensorFlow not found (Module 6)
   Solution: Install deep learning libraries: pip install torch tensorflow keras

DATASET SOURCES:
===============
- car_evaluation.csv: UCI Machine Learning Repository
- Built-in sklearn datasets: Included with scikit-learn package
- Synthetic datasets: Generated programmatically within notebooks
- California Housing: Aurelien Geron's Hands-On ML repository
- BigMart dataset: PranavTadimeti's Regression lab repository
- Mall_Customers.csv: Google Drive (Kaggle Mall Customer Segmentation dataset)
- Wholesale customers data.csv: Google Drive (UCI Wholesale Customer dataset)

MODULE-SPECIFIC REQUIREMENTS:
============================
- Module 0: numpy, matplotlib, scipy, scikit-image (for SVD image examples)
- Module 3: scipy (for Voronoi diagrams), sklearn (for KNN and scaling)  
- Module 4: matplotlib (for 2D/3D plotting), numpy, sympy (for symbolic math), scikit-learn, scipy
- Module 5: Requires internet connection for dataset downloads
- Module 6: Requires PyTorch/TensorFlow for neural network implementations
- All modules: scikit-learn, pandas, numpy, matplotlib

PROJECT-SPECIFIC VIRTUAL ENVIRONMENTS:
====================================
- mod3_project_venv: Dedicated environment for Mod3_project.ipynb (diabetes prediction)
- mod4_project_venv: Dedicated environment for Mod4_project.ipynb (gradient descent optimization)

For the most up-to-date dataset requirements, always check the import statements and file loading sections in each notebook.
